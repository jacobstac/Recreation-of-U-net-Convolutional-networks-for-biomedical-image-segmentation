{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program flow\n",
    " * Read data \n",
    "     Testfolders has subfolders 01 and 02 containing .tif\n",
    "     Trainingfolders has subfolders 01 01_GT 01_ST 02 02_GT 02_ST\n",
    "     GT has subfolders SEG and TRA ST has subfolder SEG\n",
    "     SEG contains .tif that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.ipynb\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from skimage.segmentation import flood, flood_fill, find_boundaries\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_data(folder):\n",
    "    X = []\n",
    "    Y = []\n",
    "    path = os.fsencode(folder)\n",
    "    for folder in os.listdir(path):\n",
    "        if not folder.startswith(b'.') and not folder.endswith(b'GT'):\n",
    "            inner_path = concat_path(path, folder)\n",
    "            for file in os.listdir(inner_path):\n",
    "                if not file.startswith(b'.'):\n",
    "                    file_path = concat_path(inner_path, file)\n",
    "                    im = np.array(Image.open(file_path))\n",
    "                    foo = np.expand_dims(im, axis = 2)\n",
    "                    file_id = concat_path(folder, file)\n",
    "                    point = (file_id, im)\n",
    "                    Y.append(point) if folder.endswith(b'ST') else X.append(point)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def fetch_data(folder):\n",
    "    path = os.getcwd()+'/' + folder\n",
    "    test_folder = path+'-test'\n",
    "    training_folder = path+'-training'\n",
    "    X_test, _ = read_data(test_folder)\n",
    "    X_train, Y_train = read_data(training_folder)\n",
    "    X_test.sort()\n",
    "    X_train.sort()\n",
    "    Y_train.sort()\n",
    "    \n",
    "    X_train = list(map(lambda x : x[1], X_train))\n",
    "    Y_train = list(map(lambda y : y[1], Y_train))\n",
    "    X_test = list(map(lambda x : x[1], X_test))\n",
    "    return X_test, X_train, Y_train\n",
    "\n",
    "\n",
    "def is_border(a,b):\n",
    "    return (a != 0  and a != b)\n",
    "    \n",
    "    \n",
    "def enforce_borders(labels):\n",
    "    for i in range(1,len(labels)-1):\n",
    "        for j in range(1,len(labels[0])-1):\n",
    "            curr   = labels[i][j]\n",
    "            over   = labels[i][j-1] \n",
    "            prev   = labels[i-1][j]\n",
    "            diag_1 = labels[i-1][j-1] \n",
    "            diag_2 = labels[i+1][j-1] \n",
    "            if(is_border(over,curr) or is_border(prev,curr) or is_border(diag_1,curr) or is_border(diag_2,curr)):\n",
    "                labels[i][j] = 0\n",
    "                \n",
    "    return labels\n",
    "\n",
    "\n",
    "def machine_boundries(labels):\n",
    "    a = find_boundaries(labels, mode='thick', connectivity=4)\n",
    "    for i in range(512):\n",
    "        for j in range(512):\n",
    "            if a[i,j] == 1:\n",
    "                \n",
    "                labels[i,j] = 0\n",
    "    return labels\n",
    "\n",
    "\n",
    "def reinforce_borders(masks):\n",
    "    amount = len(masks)\n",
    "    reinforced = np.zeros((amount, 512, 512))\n",
    "    print('Reinforcing borders of ', amount, 'images')\n",
    "    for i in tqdm(range(amount)):\n",
    "        enforced = enforce_borders(masks[i])\n",
    "        enhanced = machine_boundries(enforced)\n",
    "        reinforced[i] = enhanced\n",
    "    return reinforced\n",
    "\n",
    "\n",
    "def unify_all_images(masks):\n",
    "    amount = len(masks)\n",
    "    unified = np.zeros((amount, 512, 512, 1))\n",
    "    print('Unifying classes of ', amount, 'masks')\n",
    "    for i in tqdm(range(amount)):\n",
    "        unified[i] = np.minimum(masks[i], 1)\n",
    "    return unified\n",
    "\n",
    "\n",
    "def fill_classes(img):\n",
    "    img = squeeze_image(img)\n",
    "    label = 2\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            if(img[i][j] == 1):\n",
    "                img = flood_fill(img, (i, j), label)\n",
    "                label += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def adjust_dimension_to_network(data):\n",
    "    return np.expand_dims(data, axis = 3)\n",
    "\n",
    "\n",
    "def display_image(img):\n",
    "    img = squeeze_image(img)\n",
    "    imgplot = plt.imshow(img)    \n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def squeeze_image(img):\n",
    "    img = np.squeeze(img) if len(img.shape) == 4 else img\n",
    "    img = np.squeeze(img) if len(img.shape) == 3 else img\n",
    "    return img\n",
    "    \n",
    "    \n",
    "def divide_data(data, split):\n",
    "    samples = len(data)\n",
    "    index = int(samples*split)\n",
    "    test = data[index:samples]\n",
    "    train = data[0:index]\n",
    "    return train, test\n",
    "    \n",
    "    \n",
    "folder_1 = 'datasets/DIC-C2DH-HeLa'\n",
    "folder_2 = 'datasets/PhC-C2DH-U373'\n",
    "\n",
    "\n",
    "def dist_to_n_nearest(img, x, y, distance, summ):\n",
    "    not_zeros = np.argwhere(img != 0)\n",
    "    dist_matrix = distance_matrix([(x, y)], not_zeros, p=2)\n",
    "    min_distance = np.min(dist_matrix)\n",
    "    min_index = np.argmin(dist_matrix)\n",
    "    min_point = not_zeros[np.argmin(dist_matrix)]\n",
    "    min_x, min_y = min_point[0], min_point[1]\n",
    "    img = remove_cell(img, min_x, min_y)\n",
    "    if distance == 1: \n",
    "        return min_distance + summ\n",
    "    else:\n",
    "        return dist_to_n_nearest(img, x, y, distance-1, min_distance)\n",
    "    \n",
    "    \n",
    "def fill_dist_matrix(img):\n",
    "    dist_matrix = np.zeros_like(img)\n",
    "    for i in tqdm(range(len(img))):\n",
    "        for j in range(len(img[0])):\n",
    "            dist_matrix[i, j] = dist_to_n_nearest(np.copy(img), i, j, 2, 0)\n",
    "    return dist_matrix\n",
    "    \n",
    "    \n",
    "def fill_all_dist_matrices(labels):\n",
    "    dist_matrices = np.zeros_like(labels)\n",
    "    for i, label in tqdm(enumerate(labels)):\n",
    "        dist_matrices[i] = fill_dist_matrix(label)\n",
    "    return dist_matrices\n",
    "\n",
    "    \n",
    "def remove_cell(img, x, y):\n",
    "    return flood_fill(img, (x, y), 0)\n",
    "\n",
    "\n",
    "def fetch_border_weights(Y):\n",
    "    Y = squeeze_image(np.around(Y))\n",
    "    colors = np.unique(Y)\n",
    "    zero_index = np.argwhere(colors == 0)\n",
    "    colors = np.delete(colors, zero_index)\n",
    "    distance_images = np.ones((len(colors),512,512))\n",
    "    for index, color in enumerate(colors):\n",
    "        ones = np.argwhere(Y == color)\n",
    "        x, y = ones[0]\n",
    "        a = np.ones((512,512))\n",
    "        for i in ones:\n",
    "            a[i[0], i[1]] = 0\n",
    "            #display_image(a)\n",
    "        Y1 = distance_transform_edt(a)\n",
    "            #display_image(Y1)\n",
    "        distance_images[index] = Y1\n",
    "\n",
    "    distance_images = np.transpose(distance_images)\n",
    "    distance_images = np.sort(distance_images, axis=2)\n",
    "    distance_images = distance_images[:,:,0:2]\n",
    "    weights = np.sum(distance_images, axis=2)\n",
    "    return np.transpose(weights)\n",
    "\n",
    "\n",
    "def fetch_weights(masks):\n",
    "    print('Generating weight matrices for: ', len(masks), ' masks.')\n",
    "    weights = np.zeros((len(masks), 512, 512))\n",
    "    unified_masks = np.array(unify_all_images(masks))\n",
    "    class_weights = np.zeros((512, 512))\n",
    "    class_weight_scale = 512 * 512 * (len(masks)/8)\n",
    "    w1 = 1 - unified_masks.sum() / class_weight_scale\n",
    "    w2 = 1 - w1\n",
    "    avg = np.squeeze(unified_masks.sum(0))\n",
    "    class_weights[avg == 1] = w1\n",
    "    class_weights[avg == 0] = w2\n",
    "    sigma = 25\n",
    "    scale = 2 * (sigma ** 2)\n",
    "    w0 = 10\n",
    "     \n",
    "    for i, mask in tqdm(enumerate(masks)):\n",
    "        border_weights = fetch_border_weights(mask)\n",
    "        scaled_border_weights = class_weights + w0 * np.exp(-(np.power(border_weights, 2))/scale)\n",
    "        combined_weights = class_weights + scaled_border_weights\n",
    "        weights[i] = combined_weights\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this to load data and reinforce borders\n",
    "Unifying of labels is done later due to the nature of the weight calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test, X_train, Y_train = fetch_data(folder_1)\n",
    "#Y_train = reinforce_borders(Y_orig)\n",
    "\n",
    "Y_train = adjust_dimension_to_network(Y_train)\n",
    "X_train = adjust_dimension_to_network(X_train)\n",
    "X_test = adjust_dimension_to_network(X_test)\n",
    "#Y_train = unify_all_images(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this to create augmentations and calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                                 | 1/168 [00:00<00:17,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating  504  augmentations of  168  images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 168/168 [00:16<00:00, 10.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 168/168 [00:12<00:00, 13.80it/s]\n",
      " 16%|█████████████                                                                   | 82/504 [00:00<00:01, 407.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unifying classes of  504 masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 504/504 [00:01<00:00, 397.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen_args = dict(rotation_range=0.2,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "seed = 1\n",
    "\n",
    "datagen_X = ImageDataGenerator(**datagen_args)\n",
    "datagen_Y = ImageDataGenerator(**datagen_args)\n",
    "  \n",
    "datagen_X.fit(X_train, augment=True, seed=seed)\n",
    "datagen_Y.fit(Y_train, augment=True, seed=seed)\n",
    "\n",
    "amount_of_images = len(X_train)\n",
    "augmentations = 3\n",
    "amount_of_new_images = amount_of_images * augmentations\n",
    "X_new = np.ones((amount_of_new_images, 512, 512, 1))\n",
    "Y_new = np.ones((amount_of_new_images, 512, 512, 1))\n",
    "\n",
    "\n",
    "print('Creating ', amount_of_new_images, ' augmentations of ', amount_of_images, ' images')\n",
    "for j in tqdm(range(amount_of_images)):\n",
    "    i = 0\n",
    "    for x_batch in datagen_X.flow(X_train[j:j+1], batch_size=1, seed=seed):\n",
    "        if(i >= augmentations):\n",
    "            break\n",
    "        save_index = j * augmentations + i\n",
    "        X_new[save_index] = np.around(x_batch)\n",
    "        #display_image(x_batch)\n",
    "        i +=1\n",
    "        \n",
    "for j in tqdm(range(amount_of_images)):\n",
    "    i = 0\n",
    "    for y_batch in datagen_Y.flow(Y_train[j:j+1], batch_size=1, seed=seed):\n",
    "        if(i >= augmentations):\n",
    "            break\n",
    "        save_index = j * augmentations + i\n",
    "        Y_new[save_index] = np.around(y_batch)\n",
    "        #display_image(y_batch)\n",
    "        i +=1\n",
    "        \n",
    "import pickle\n",
    "#pickle_out = open(\"X_with_augmentations.pkl\",\"wb\")\n",
    "#pickle.dump(X_new, pickle_out)        \n",
    "\n",
    "#weights = fetch_weights(Y_new)\n",
    "\n",
    "Y_new_unified = unify_all_images(Y_new)\n",
    "\n",
    "#pickle_out = open(\"Y_with_augmentations.pkl\",\"wb\")\n",
    "#pickle.dump(Y_new_unified, pickle_out)        \n",
    "\n",
    "#pickle_out = open(\"weights.pkl\",\"wb\")\n",
    "#pickle.dump(weights, pickle_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples, validate on 51 samples\n",
      "Epoch 1/25\n",
      "453/453 [==============================] - 112s 248ms/sample - loss: 0.7101 - get_f1: 0.2715 - val_loss: 0.7107 - val_get_f1: 0.0122\n",
      "Epoch 2/25\n",
      "453/453 [==============================] - 111s 245ms/sample - loss: 0.7083 - get_f1: 0.2995 - val_loss: 0.7078 - val_get_f1: 0.0288\n",
      "Epoch 3/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7067 - get_f1: 0.3254 - val_loss: 0.7055 - val_get_f1: 0.0655\n",
      "Epoch 4/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7053 - get_f1: 0.3492 - val_loss: 0.7035 - val_get_f1: 0.1268\n",
      "Epoch 5/25\n",
      "453/453 [==============================] - 111s 245ms/sample - loss: 0.7043 - get_f1: 0.3704 - val_loss: 0.7017 - val_get_f1: 0.1926\n",
      "Epoch 6/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7034 - get_f1: 0.3905 - val_loss: 0.7001 - val_get_f1: 0.2571\n",
      "Epoch 7/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7027 - get_f1: 0.4064 - val_loss: 0.6989 - val_get_f1: 0.3103\n",
      "Epoch 8/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7021 - get_f1: 0.4215 - val_loss: 0.6978 - val_get_f1: 0.3625\n",
      "Epoch 9/25\n",
      "453/453 [==============================] - 111s 246ms/sample - loss: 0.7016 - get_f1: 0.4344 - val_loss: 0.6968 - val_get_f1: 0.4120\n",
      "Epoch 10/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7012 - get_f1: 0.4456 - val_loss: 0.6960 - val_get_f1: 0.4530\n",
      "Epoch 11/25\n",
      "453/453 [==============================] - 111s 244ms/sample - loss: 0.7009 - get_f1: 0.4554 - val_loss: 0.6953 - val_get_f1: 0.4855\n",
      "Epoch 12/25\n",
      "453/453 [==============================] - 111s 245ms/sample - loss: 0.7006 - get_f1: 0.4649 - val_loss: 0.6946 - val_get_f1: 0.5144\n",
      "Epoch 13/25\n",
      "264/453 [================>.............] - ETA: 44s - loss: 0.7004 - get_f1: 0.4717"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import smart_cond\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "def conv2D_layer(filters):\n",
    "    return tf.keras.layers.Conv2D(filters, (3, 3), activation='relu', kernel_initializer = 'he_normal', padding = 'same')\n",
    "\n",
    "inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
    "\n",
    "s = tf.keras.layers.Lambda(lambda x : x / 255)(inputs)\n",
    "\n",
    "#Contraction path\n",
    "c1 = conv2D_layer(64)(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = conv2D_layer(64)(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "c2 = conv2D_layer(128)(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = conv2D_layer(128)(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3 = conv2D_layer(256)(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.1)(c3)\n",
    "c3 = conv2D_layer(256)(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n",
    "\n",
    "c4 = conv2D_layer(512)(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = conv2D_layer(512)(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n",
    "\n",
    "c5 = conv2D_layer(1024)(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = conv2D_layer(1024)(c5)\n",
    "\n",
    "#Expansive path\n",
    "u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides = (2,2), padding = 'same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = conv2D_layer(512)(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = conv2D_layer(512)(c6)\n",
    "\n",
    "u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides = (2,2), padding = 'same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = conv2D_layer(256)(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = conv2D_layer(256)(c7)\n",
    "\n",
    "u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides = (2,2), padding = 'same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = conv2D_layer(128)(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = conv2D_layer(128)(c8)\n",
    "\n",
    "u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides = (2,2), padding = 'same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "c9 = conv2D_layer(64)(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = conv2D_layer(64)(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation = 'sigmoid')(c9)\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('backup_model.h5', verbose = 1, save_best_only = True)\n",
    "\n",
    "callbacks = [ \n",
    "    tf.keras.callbacks.EarlyStopping(patience = 4, monitor = 'loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]\n",
    "\n",
    "\n",
    "def cast_y(y_true, y_pred):\n",
    "    y_pred = ops.convert_to_tensor_v2(y_pred)\n",
    "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "def transformer(x):\n",
    "    x.numpy()\n",
    "    return x\n",
    "\n",
    "\n",
    "def balanced_cross_entropy(beta):\n",
    "    def convert_to_logits(y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "        return tf.math.log(y_pred / (1 - y_pred))\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = ops.convert_to_tensor_v2(y_pred)\n",
    "        y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "        \n",
    "        y_pred = convert_to_logits(y_pred)\n",
    "        pos_weight = beta / (1 - beta)\n",
    "        loss = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred, labels=y_true, pos_weight=pos_weight)\n",
    "        return tf.reduce_mean(loss * (1 - beta))\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def energy_loss(y_true, y_pred):\n",
    "    #bca = balanced_cross_entropy(0.8)(y_true, y_pred)\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)\n",
    "\n",
    "_epsilon = tf.convert_to_tensor(K.epsilon(), np.float32)\n",
    "\n",
    "c11 = tf.keras.layers.Lambda(lambda x: x / tf.reduce_sum(x, len(x.get_shape()) - 1, True))(outputs)\n",
    "c11 = tf.keras.layers.Lambda(lambda x: tf.clip_by_value(x, _epsilon, 1. - _epsilon))(c11)\n",
    "c11 = tf.keras.layers.Lambda(lambda x: K.log(x))(c11)\n",
    "weight_ip = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
    "weighted_sm = tf.keras.layers.multiply([c11, weight_ip])\n",
    "\n",
    "def my_loss(target, output):\n",
    "        return tf.reduce_sum(target * output, len(output.get_shape()) - 1)\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=1e-7, decay=1e-6, momentum=0.99, nesterov=True)\n",
    "#model = tf.keras.Model(inputs = [inputs, weight_ip], outputs = [weighted_sm])\n",
    "model = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n",
    "model.compile(optimizer = sgd , loss = 'binary_crossentropy', metrics=[get_f1])\n",
    "#model.summary()\n",
    "\n",
    "#pickle_out = open(\"X_with_augmentations.pkl\",\"wb\")\n",
    "#X_new = pickle.load(X_new, pickle_out)        \n",
    "\n",
    "#pickle_out = open(\"Y_with_augmentations.pkl\",\"wb\")\n",
    "#Y_new = pickle.load(Y_new_unified, pickle_out)        \n",
    "\n",
    "#pickle_out = open(\"weights.pkl\",\"wb\")\n",
    "#weights = pickle.load(weights, pickle_out)    \n",
    "\n",
    "#results = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=1), epochs=25, callbacks = callbacks)\n",
    "#X_white = np.ones((lenght, 512, 512, 1))\n",
    "results = model.fit(X_new, Y_new_unified, validation_split = 0.1, batch_size = 1, epochs = 25, callbacks = callbacks)\n",
    "#results = model.fit((X_new, adjust_dimension_to_network(weights)), Y_new_unified, validation_split = 0.1, batch_size = 1, epochs = 25, callbacks = callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = Y_new_unified[0]\n",
    "colors = np.unique(foo)\n",
    "\n",
    "display_image(X_new[0])\n",
    "display_image(np.around(X_new[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colorsX = np.unique(np.around(X_new[0]))\n",
    "print(len(colors))\n",
    "for i in range(60):\n",
    "    print(np.unique(Y_new_unified[i]))\n",
    "    print(len(np.unique(Y_new_unified[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(weights[0])\n",
    "display_image(Y_new_unified[0])\n",
    "im = np.expand_dims(X_new[0], axis=3)\n",
    "\n",
    "z = np.ones((1, 512, 512, 1))\n",
    "print(\"hehehe\"+str(weights[0:1].shape))\n",
    "predictions = model.predict([X_new[0:1], z])\n",
    "#predictions = model.predict(X_train)\n",
    "\n",
    "\n",
    "display_image(X_new[0])\n",
    "#print(X_train[0])\n",
    "foo = np.squeeze(predictions[0])\n",
    "display_image(foo)\n",
    "border = 0.55\n",
    "foo[foo < border] = 0\n",
    "foo[foo >= border] = 123\n",
    "print(foo)\n",
    "display_image(foo)\n",
    "print(len(predictions[0].shape))\n",
    "\n",
    "foo = foo ** 10\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 683.6250202655792,
   "position": {
    "height": "40px",
    "left": "45.875px",
    "right": "20px",
    "top": "117.95833587646484px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
